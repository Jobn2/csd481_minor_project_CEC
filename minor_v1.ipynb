{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT_J6zsXIy1v",
        "outputId": "93c1aa53-2fb8-4fcf-a3fb-ddd3731cfa9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "!pip install nltk\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload Fake.csv and True.csv manually in Colab\n",
        "\n",
        "fake = pd.read_csv(\"Fake.csv\", on_bad_lines='skip', encoding='latin-1', engine='python')\n",
        "real = pd.read_csv(\"True.csv\", on_bad_lines='skip', encoding='latin-1', engine='python')\n",
        "\n",
        "print(\"✅ Fake dataset shape:\", fake.shape)\n",
        "print(\"✅ Real dataset shape:\", real.shape)\n",
        "\n",
        "print(\"\\nFake news sample:\")\n",
        "print(fake.head(2))\n",
        "print(\"\\nReal news sample:\")\n",
        "print(real.head(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYlwOGjqI87l",
        "outputId": "1d27237e-49de-4431-92c9-12891c5170fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fake dataset shape: (403, 4)\n",
            "✅ Real dataset shape: (828, 4)\n",
            "\n",
            "Fake news sample:\n",
            "                                               title  \\\n",
            "0   Donald Trump Sends Out Embarrassing New Yearâ...   \n",
            "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
            "\n",
            "                                                text subject  \\\n",
            "0  Donald Trump just couldn t wish all Americans ...    News   \n",
            "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
            "\n",
            "                date  \n",
            "0  December 31, 2017  \n",
            "1  December 31, 2017  \n",
            "\n",
            "Real news sample:\n",
            "                                               title  \\\n",
            "0  As U.S. budget fight looms, Republicans flip t...   \n",
            "1  U.S. military to accept transgender recruits o...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
            "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
            "\n",
            "                 date  \n",
            "0  December 31, 2017   \n",
            "1  December 29, 2017   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add labels\n",
        "fake[\"label\"] = 1   # Fake news\n",
        "real[\"label\"] = 0   # Real news\n",
        "\n",
        "# Use only \"text\" column (drop unused)\n",
        "df = pd.concat([fake[[\"text\",\"label\"]], real[[\"text\",\"label\"]]], ignore_index=True)\n",
        "\n",
        "print(\"✅ Combined dataset shape:\", df.shape)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPEGMFgzJSRG",
        "outputId": "6ed0bb4b-d02d-4f79-c865-cc815f63fde6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Combined dataset shape: (1231, 2)\n",
            "                                                text  label\n",
            "0  Donald Trump just couldn t wish all Americans ...      1\n",
            "1  House Intelligence Committee Chairman Devin Nu...      1\n",
            "2  On Friday, it was revealed that former Milwauk...      1\n",
            "3  On Christmas day, Donald Trump announced that ...      1\n",
            "4  Pope Francis used his annual Christmas Day mes...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kikWtaPNJleb",
        "outputId": "58cd53d2-641b-48a2-a29b-ade9a25600f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation, numbers, special characters\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Remove stopwords + lemmatize\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "df[\"clean_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "print(\"✅ Preprocessing done\")\n",
        "print(df[[\"text\",\"clean_text\"]].head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHPn-fchJWts",
        "outputId": "e1392980-87a8-4a27-f81c-c9f01fe06bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Preprocessing done\n",
            "                                                text  \\\n",
            "0  Donald Trump just couldn t wish all Americans ...   \n",
            "1  House Intelligence Committee Chairman Devin Nu...   \n",
            "2  On Friday, it was revealed that former Milwauk...   \n",
            "\n",
            "                                          clean_text  \n",
            "0  donald trump wish american happy new year leav...  \n",
            "1  house intelligence committee chairman devin nu...  \n",
            "2  friday revealed former milwaukee sheriff david...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GAR6U71cSuAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X = df[\"clean_text\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_df=0.7)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"✅ Vectorization complete:\", X_train_vec.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rJn5bhsJpxW",
        "outputId": "d29f2afa-645e-47fd-d073-0e68b2f48ecb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Vectorization complete: (984, 18849)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "print(\"✅ Model Training Complete\")\n",
        "print(\"Accuracy:\", model.score(X_test_vec, y_test))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HqL57_oJxCu",
        "outputId": "84832e02-451a-478d-a1e9-61b3eea46ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model Training Complete\n",
            "Accuracy: 0.9635627530364372\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       162\n",
            "           1       1.00      0.89      0.94        85\n",
            "\n",
            "    accuracy                           0.96       247\n",
            "   macro avg       0.97      0.95      0.96       247\n",
            "weighted avg       0.97      0.96      0.96       247\n",
            "\n"
          ]
        }
      ]
    }
  ]
}